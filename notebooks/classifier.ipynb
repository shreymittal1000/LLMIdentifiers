{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc76cbf-0250-4606-a819-a62f04825be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefc40af-3c11-4ea9-88e8-d94fa7e29c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4218 valid JSON result files from '../results/base/' and its subfolders.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "folder_path = \"../results/base/\"\n",
    "data = []\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    entry = json.load(f)\n",
    "                    data.append(entry)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipped invalid JSON: {file_path} ({e})\")\n",
    "\n",
    "print(f\"Loaded {len(data)} valid JSON result files from '{folder_path}' and its subfolders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5164b6ce-e20a-4ea0-b184-aaebf03761f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying 8436 guess reasonings using 16 threads...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying batches:   0%|                                                                                                                                              | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Failed to parse LLM output ---\n",
      "{\n",
      "  \"Reasoning_behind_classification\": \"The justification highlights the other model's adherence to a specific, repeated pattern of behavior ('repeatedly tried to reverse the typical AI assistant interaction', 'persistent, somewhat scripted behavior', 'consistent pattern'). This focus on the predictable and systematic nature of the interaction points to a 'Highly structured' strategy. While there's an element of understanding the context of the interaction ('despite my clear statements that I am an AI assistant'), the primary emphasis\n",
      "----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [25:49<00:00, 96.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1.  SETUP – strategy dictionary and OpenRouter helper\n",
    "# ------------------------------------------------------------------\n",
    "import json, time, backoff, pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# ••• fill in your key here •••\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# 3 strategies per model (use None for “N/A” placeholders)\n",
    "MODEL_STRATEGIES = {\n",
    "    \"claude\":  [\"Identity reveal\",\n",
    "                \"Insistent on being an assistant\",\n",
    "                \"Very meticulous in explanations\"],\n",
    "    \"deepseek\":[\"Identity reveal\",\n",
    "                \"Precise communication style\",\n",
    "                None],                            # only two real ones\n",
    "    \"gemini\":  [\"Creative storytelling\",\n",
    "                \"Engaging conversation\",\n",
    "                \"Technical and ethical acumen\"],\n",
    "    \"gpt\":     [\"Highly structured\",\n",
    "                \"Contextual understanding\",\n",
    "                \"Adaptability\"],\n",
    "    \"llama\":   [\"Less sophisticated\",\n",
    "                \"Open-source\",\n",
    "                \"Nuanced understanding\"],\n",
    "    \"mistral\": [\"Task capabilities\",\n",
    "                \"Concise and simple\",\n",
    "                \"Friendly\"],\n",
    "    \"qwen\":    [\"China-relevant knowledge\",\n",
    "                \"Formal, educational\",\n",
    "                \"Rigid conversation\"],\n",
    "}\n",
    "\n",
    "# helper → nice list without Nones\n",
    "def strategies_for(model):\n",
    "    return [s for s in MODEL_STRATEGIES[model] if s]\n",
    "\n",
    "class ORClient:\n",
    "    def __init__(self, api_key, model=\"google/gemini-2.5-flash-preview\", min_interval=1.5):\n",
    "        self.cli = OpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "        self.model = model\n",
    "        self.min_interval = min_interval  # <- critical line\n",
    "        self.last = 0\n",
    "\n",
    "    @backoff.on_exception(backoff.expo, Exception, max_tries=6)\n",
    "    def classify(self, prompt):\n",
    "        wait = self.min_interval - (time.time() - self.last)\n",
    "        if wait > 0:\n",
    "            time.sleep(wait)\n",
    "    \n",
    "        res = self.cli.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=300,\n",
    "            temperature=0,\n",
    "        )\n",
    "        self.last = time.time()\n",
    "        text = res.choices[0].message.content.strip()\n",
    "    \n",
    "        # Try extracting the JSON object\n",
    "        try:\n",
    "            # Remove triple-backtick code block wrappers\n",
    "            if text.startswith(\"```json\"):\n",
    "                text = text[7:].strip(\"` \\n\")\n",
    "            elif text.startswith(\"```\"):\n",
    "                text = text[3:].strip(\"` \\n\")\n",
    "    \n",
    "            # Find first { ... }\n",
    "            json_start = text.find(\"{\")\n",
    "            json_end = text.rfind(\"}\") + 1\n",
    "            json_str = text[json_start:json_end]\n",
    "    \n",
    "            return json.loads(json_str)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"\\n--- Failed to parse LLM output ---\")\n",
    "            print(text)\n",
    "            print(\"----------------------------------\\n\")\n",
    "            return {\n",
    "                \"Reasoning_behind_classification\": f\"Failed to parse: {text}\",\n",
    "                \"Strategies\": [\"Failed to parse\"]\n",
    "            }\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  BUILD THE CLASSIFICATION PROMPT\n",
    "# ------------------------------------------------------------------\n",
    "def build_prompt(reasoning, guessed_model):\n",
    "    allowed = strategies_for(guessed_model)\n",
    "    allowed_str = \"\\n\".join(f\"{i+1}. {s}\" for i, s in enumerate(allowed))\n",
    "    return f\"\"\"You are judging WHY a language model guessed another model.\n",
    "\n",
    "The guessed model: **{guessed_model}**\n",
    "\n",
    "Classify the justification below into ANY of these strategies\n",
    "(you may output multiple, or \"Other\" if none fit):\n",
    "\n",
    "{allowed_str}\n",
    "\n",
    "Justification:\n",
    "\\\"\\\"\\\"{reasoning}\\\"\\\"\\\"\n",
    "\n",
    "Return ONLY valid JSON like:\n",
    "{{  \n",
    "  \"Reasoning_behind_classification\": \"...explanation...\",\n",
    "  \"Strategies\": [\"{allowed[0]}\", \"{allowed[1]}\"]\n",
    "}}\"\"\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  EXTRACT (reasoning, guess) PAIRS FROM ALL TRIALS\n",
    "# ------------------------------------------------------------------\n",
    "def extract_pairs(trials):\n",
    "    pairs = []\n",
    "    for t in trials:\n",
    "        for agent_id in [\"agent_0\", \"agent_1\"]:\n",
    "            reasoning = (t.get(f\"{agent_id}_answer\") or \"\").strip()\n",
    "            guess = (t.get(f\"{agent_id}_guess\") or \"\").strip().lower()\n",
    "            if reasoning and guess in MODEL_STRATEGIES:\n",
    "                pairs.append({\n",
    "                    \"guesser\": agent_id,\n",
    "                    \"guessed_model\": guess,\n",
    "                    \"reasoning\": reasoning,\n",
    "                    \"trial_id\": t.get(\"seed\", \"na\")\n",
    "                })\n",
    "    return pairs\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  RUN EVERYTHING\n",
    "# ------------------------------------------------------------------\n",
    "from tqdm import tqdm  # for notebook-style progress bar\n",
    "\n",
    "def run_classification(all_trials):\n",
    "    client = ORClient(OPENROUTER_API_KEY)\n",
    "    pairs = extract_pairs(all_trials)\n",
    "    print(len(pairs))\n",
    "    rows = []\n",
    "\n",
    "    print(f\"Classifying {len(pairs)} guess reasonings...\\n\")\n",
    "\n",
    "    for p in tqdm(pairs, desc=\"Classifying guesses\"):\n",
    "        prompt = build_prompt(p[\"reasoning\"], p[\"guessed_model\"])\n",
    "        result = client.classify(prompt)\n",
    "        rows.append({\n",
    "            **p,\n",
    "            \"strategies\": \", \".join(result.get(\"Strategies\", [])),\n",
    "            \"judge_explanation\": result.get(\"Reasoning_behind_classification\", \"\")\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "def run_classification_parallel(all_trials, api_key, max_workers=4):\n",
    "    from copy import deepcopy\n",
    "\n",
    "    pairs = extract_pairs(all_trials)\n",
    "    print(f\"Classifying {len(pairs)} guess reasonings using {max_workers} threads...\\n\")\n",
    "\n",
    "    # Shared input split into batches\n",
    "    batch_size = math.ceil(len(pairs) / max_workers)\n",
    "    batches = [pairs[i:i + batch_size] for i in range(0, len(pairs), batch_size)]\n",
    "\n",
    "    # Create clients per worker\n",
    "    clients = [ORClient(api_key) for _ in range(len(batches))]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    def classify_batch(batch, client):\n",
    "        batch_results = []\n",
    "        for p in batch:\n",
    "            prompt = build_prompt(p[\"reasoning\"], p[\"guessed_model\"])\n",
    "            result = client.classify(prompt)\n",
    "            batch_results.append({\n",
    "                **p,\n",
    "                \"strategies\": \", \".join(result.get(\"Strategies\", [])),\n",
    "                \"judge_explanation\": result.get(\"Reasoning_behind_classification\", \"\")\n",
    "            })\n",
    "        return batch_results\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(classify_batch, batch, clients[i])\n",
    "            for i, batch in enumerate(batches)\n",
    "        ]\n",
    "\n",
    "        results = []\n",
    "        with tqdm(total=len(futures), desc=\"Classifying batches\") as pbar:\n",
    "            for f in concurrent.futures.as_completed(futures):\n",
    "                results.extend(f.result())\n",
    "                pbar.update(1)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5.  DO IT 🚀\n",
    "# ------------------------------------------------------------------\n",
    "# classified_df = run_classification(data)   # <-- your list of dicts\n",
    "# classified_df.to_csv(\"guess_strategy_labels.csv\", index=False)\n",
    "# classified_df.head()\n",
    "classified_df = run_classification_parallel(data, OPENROUTER_API_KEY, max_workers=16)\n",
    "classified_df.to_csv(\"classified_model_guess_strategies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409782bb-b721-42bc-b36d-176d955171de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guessed_model</th>\n",
       "      <th>strategy_list</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude</td>\n",
       "      <td>Identity reveal</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude</td>\n",
       "      <td>Insistent on being an assistant</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude</td>\n",
       "      <td>Very meticulous in explanations</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude</td>\n",
       "      <td>Other/Unclear</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude</td>\n",
       "      <td>Insistent on being an an assistant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek</td>\n",
       "      <td>Precise communication style</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepseek</td>\n",
       "      <td>Identity reveal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini</td>\n",
       "      <td>Engaging conversation</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gemini</td>\n",
       "      <td>Technical and ethical acumen</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini</td>\n",
       "      <td>Creative storytelling</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt</td>\n",
       "      <td>Contextual understanding</td>\n",
       "      <td>4472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt</td>\n",
       "      <td>Highly structured</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt</td>\n",
       "      <td>Adaptability</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt</td>\n",
       "      <td>Other/Unclear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>llama</td>\n",
       "      <td>Nuanced understanding</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama</td>\n",
       "      <td>Less sophisticated</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>llama</td>\n",
       "      <td>Open-source</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mistral</td>\n",
       "      <td>Task capabilities</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mistral</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mistral</td>\n",
       "      <td>Concise and simple</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qwen</td>\n",
       "      <td>Formal</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qwen</td>\n",
       "      <td>educational</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qwen</td>\n",
       "      <td>China-relevant knowledge</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qwen</td>\n",
       "      <td>Rigid conversation</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qwen</td>\n",
       "      <td>Other/Unclear</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   guessed_model                       strategy_list  count\n",
       "0         claude                     Identity reveal   1029\n",
       "2         claude     Insistent on being an assistant    585\n",
       "4         claude     Very meticulous in explanations    449\n",
       "3         claude                       Other/Unclear      5\n",
       "1         claude  Insistent on being an an assistant      1\n",
       "6       deepseek         Precise communication style      2\n",
       "5       deepseek                     Identity reveal      1\n",
       "8         gemini               Engaging conversation    994\n",
       "9         gemini        Technical and ethical acumen    389\n",
       "7         gemini               Creative storytelling    180\n",
       "11           gpt            Contextual understanding   4472\n",
       "12           gpt                   Highly structured   2880\n",
       "10           gpt                        Adaptability    837\n",
       "13           gpt                       Other/Unclear      1\n",
       "15         llama               Nuanced understanding    781\n",
       "14         llama                  Less sophisticated     28\n",
       "16         llama                         Open-source     16\n",
       "19       mistral                   Task capabilities    283\n",
       "18       mistral                            Friendly     46\n",
       "17       mistral                  Concise and simple     32\n",
       "21          qwen                              Formal    101\n",
       "24          qwen                         educational    101\n",
       "20          qwen            China-relevant knowledge     74\n",
       "23          qwen                  Rigid conversation     32\n",
       "22          qwen                       Other/Unclear      4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"classified_model_guess_strategies.csv\")\n",
    "df.head()\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "# Expand the comma-separated strategy strings into lists\n",
    "df[\"strategy_list\"] = df[\"strategies\"].fillna(\"\").apply(lambda s: [x.strip() for x in s.split(\",\") if x.strip()])\n",
    "\n",
    "collapsed = df.explode(\"strategy_list\")\n",
    "collapsed[\"strategy_list\"] = collapsed[\"strategy_list\"].replace({\n",
    "    \"Other\": \"Other/Unclear\", \n",
    "    \"Failed to parse\": \"Other/Unclear\"\n",
    "})\n",
    "\n",
    "# Count occurrences per guessed model\n",
    "model_strategy_counts = (\n",
    "    collapsed.explode(\"strategy_list\")\n",
    "      .groupby([\"guessed_model\", \"strategy_list\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"count\")\n",
    "      .sort_values([\"guessed_model\", \"count\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "model_strategy_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f86a28d2-50b6-4ca1-95a9-c0d73c06d224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guessed_model</th>\n",
       "      <th>strategy_list</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude</td>\n",
       "      <td>Identity reveal</td>\n",
       "      <td>49.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude</td>\n",
       "      <td>Insistent on being an assistant</td>\n",
       "      <td>28.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude</td>\n",
       "      <td>Very meticulous in explanations</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek</td>\n",
       "      <td>Identity reveal</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepseek</td>\n",
       "      <td>Precise communication style</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gemini</td>\n",
       "      <td>Creative storytelling</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini</td>\n",
       "      <td>Engaging conversation</td>\n",
       "      <td>63.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini</td>\n",
       "      <td>Technical and ethical acumen</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt</td>\n",
       "      <td>Adaptability</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt</td>\n",
       "      <td>Contextual understanding</td>\n",
       "      <td>54.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt</td>\n",
       "      <td>Failed to parse</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt</td>\n",
       "      <td>Highly structured</td>\n",
       "      <td>35.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>llama</td>\n",
       "      <td>Less sophisticated</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama</td>\n",
       "      <td>Nuanced understanding</td>\n",
       "      <td>94.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>llama</td>\n",
       "      <td>Open-source</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mistral</td>\n",
       "      <td>Concise and simple</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mistral</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mistral</td>\n",
       "      <td>Task capabilities</td>\n",
       "      <td>78.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>qwen</td>\n",
       "      <td>China-relevant knowledge</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qwen</td>\n",
       "      <td>Formal</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qwen</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qwen</td>\n",
       "      <td>Rigid conversation</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qwen</td>\n",
       "      <td>educational</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   guessed_model                    strategy_list  percent\n",
       "0         claude                  Identity reveal     49.7\n",
       "1         claude  Insistent on being an assistant     28.3\n",
       "2         claude                            Other      0.2\n",
       "3         claude  Very meticulous in explanations     21.7\n",
       "4       deepseek                  Identity reveal     33.3\n",
       "5       deepseek      Precise communication style     66.7\n",
       "6         gemini            Creative storytelling     11.5\n",
       "7         gemini            Engaging conversation     63.6\n",
       "8         gemini     Technical and ethical acumen     24.9\n",
       "9            gpt                     Adaptability     10.2\n",
       "10           gpt         Contextual understanding     54.6\n",
       "11           gpt                  Failed to parse      0.0\n",
       "12           gpt                Highly structured     35.2\n",
       "13         llama               Less sophisticated      3.4\n",
       "14         llama            Nuanced understanding     94.7\n",
       "15         llama                      Open-source      1.9\n",
       "16       mistral               Concise and simple      8.9\n",
       "17       mistral                         Friendly     12.7\n",
       "18       mistral                Task capabilities     78.4\n",
       "19          qwen         China-relevant knowledge     23.7\n",
       "20          qwen                           Formal     32.4\n",
       "21          qwen                            Other      1.3\n",
       "22          qwen               Rigid conversation     10.3\n",
       "23          qwen                      educational     32.4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Copy your count_df if needed\n",
    "percent_df = count_df.copy()\n",
    "\n",
    "# Step 2: Calculate total counts per model\n",
    "model_totals = (\n",
    "    percent_df.groupby(\"guessed_model\")[\"count\"]\n",
    "    .sum()\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Step 3: Add a percent column\n",
    "percent_df[\"percent\"] = percent_df.apply(\n",
    "    lambda row: 100 * row[\"count\"] / model_totals[row[\"guessed_model\"]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step 4: Round for clean display\n",
    "percent_df[\"percent\"] = percent_df[\"percent\"].round(1)\n",
    "\n",
    "# Fix duplicate typo (optional)\n",
    "percent_df[\"strategy_list\"] = percent_df[\"strategy_list\"].replace({\n",
    "    \"Insistent on being an an assistant\": \"Insistent on being an assistant\"\n",
    "})\n",
    "\n",
    "# Then re-aggregate if needed:\n",
    "percent_df = (\n",
    "    percent_df.groupby([\"guessed_model\", \"strategy_list\"], as_index=False)[\"percent\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "percent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1e3e9-443f-40e1-ae86-1dae1e8d6ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python LLMIdentifiersEnv",
   "language": "python",
   "name": "llmidentifiersenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
