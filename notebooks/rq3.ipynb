{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99d0d45-50dc-4064-a25f-a5ec5ac4fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from convokit import Corpus, Utterance, Speaker, PolitenessStrategies, Coordination, TextParser\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34394a-37ca-4f02-86fd-b5af58f95e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 145 valid JSON result files from 'results/' and its subfolders.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "folder_path = \"results/base/\"\n",
    "data = []\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    entry = json.load(f)\n",
    "                    data.append(entry)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipped invalid JSON: {file_path} ({e})\")\n",
    "\n",
    "print(f\"Loaded {len(data)} valid JSON result files from '{folder_path}' and its subfolders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a08155-355a-42df-91e6-274b69d86766",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = []\n",
    "speakers = {}\n",
    "conversation_idx = 0\n",
    "\n",
    "for log in data:\n",
    "    model_0 = log['model_general_name_0']\n",
    "    model_1 = log['model_general_name_1']\n",
    "    dialogue = log['dialogue']\n",
    "    conv_id = f\"conv_{conversation_idx}\"\n",
    "    conversation_idx += 1\n",
    "\n",
    "    for model in [model_0, model_1]:\n",
    "        if model not in speakers:\n",
    "            speakers[model] = Speaker(id=model)\n",
    "\n",
    "    for i, turn in enumerate(dialogue):\n",
    "        speaker_id = model_0 if turn['role'] == 'agent_0' else model_1\n",
    "        utterances.append(Utterance(\n",
    "            id=str(uuid.uuid4()),\n",
    "            speaker=speakers[speaker_id],\n",
    "            conversation_id=conv_id,\n",
    "            reply_to=None if i == 0 else utterances[-1].id,\n",
    "            text=turn['content'],\n",
    "            meta={\"role\": turn['role']}\n",
    "        ))\n",
    "\n",
    "# Create corpus from utterances only (speakers auto-inferred)\n",
    "corpus = Corpus(utterances=utterances)\n",
    "\n",
    "# Required for linguistic features\n",
    "parser = TextParser()\n",
    "corpus = parser.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27243e59-3e27-4604-a9bf-8d9cab3f25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze politeness\n",
    "ps = PolitenessStrategies()\n",
    "corpus = ps.transform(corpus)\n",
    "\n",
    "# Step 1: Aggregate politeness per speaker\n",
    "politeness_counts = defaultdict(lambda: {'polite': 0, 'total': 0})\n",
    "\n",
    "for utt in corpus.iter_utterances():\n",
    "    speaker = utt.speaker.id\n",
    "    if 'politeness_strategies' in utt.meta:\n",
    "        num_strategies = sum(utt.meta['politeness_strategies'].values())\n",
    "        politeness_counts[speaker]['polite'] += num_strategies > 0\n",
    "        politeness_counts[speaker]['total'] += 1\n",
    "\n",
    "output_dict = {}\n",
    "speakers = list(politeness_counts.keys())\n",
    "for speaker in speakers:\n",
    "    output_dict[speaker] = {}\n",
    "    output_dict[speaker]['Politeness'] = politeness_counts[speaker]['polite'] / politeness_counts[speaker]['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0731e2ae-a4aa-43f8-a425-8ef16caf1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze coordination\n",
    "co = Coordination()\n",
    "corpus = co.fit_transform(corpus)\n",
    "\n",
    "# Compute average coordination and standard deviation\n",
    "coord_scores = defaultdict(list)\n",
    "\n",
    "for speaker in corpus.iter_speakers():\n",
    "    if 'coord' in speaker.meta:\n",
    "        for target, sub_scores in speaker.meta['coord'].items():\n",
    "            if isinstance(sub_scores, dict):\n",
    "                values = [v for v in sub_scores.values() if v is not None]\n",
    "                if values:\n",
    "                    avg_score = np.mean(values)\n",
    "                    coord_scores[speaker.id].append(avg_score)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "for speaker, scores in coord_scores.items():\n",
    "    output_dict[speaker][\"Coordination\"] = str(np.mean(scores).round(3)) + \" ± \" + str(np.std(scores).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08643d99-5c23-4bc4-b667-02d48213faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      " & Politeness & Coordination \\\\\n",
      "\\midrule\n",
      "llama & 1.000 & 0.003 ± 0.003 \\\\\n",
      "qwen & 0.829 & -0.021 ± 0.022 \\\\\n",
      "deepseek & 0.957 & -0.016 ± 0.016 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.DataFrame(output_dict).T\n",
    "output_df['Politeness'] = output_df['Politeness'].map(lambda x: f\"{round(x, 3):.3f}\")\n",
    "print(output_df.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python LLMIdentifiersEnv",
   "language": "python",
   "name": "llmidentifiersenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
