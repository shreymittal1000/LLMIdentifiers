{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc76cbf-0250-4606-a819-a62f04825be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefc40af-3c11-4ea9-88e8-d94fa7e29c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4218 valid JSON result files from '../results/base/' and its subfolders.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "folder_path = \"../results/base/\"\n",
    "data = []\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    entry = json.load(f)\n",
    "                    data.append(entry)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipped invalid JSON: {file_path} ({e})\")\n",
    "\n",
    "print(f\"Loaded {len(data)} valid JSON result files from '{folder_path}' and its subfolders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5164b6ce-e20a-4ea0-b184-aaebf03761f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying 8436 guess reasonings using 16 threads...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying batches:   0%|                                                                                                                                              | 0/16 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ORClient' object has no attribute 'min_interval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 202\u001b[39m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(results)\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# 5.  DO IT 🚀\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# classified_df = run_classification(data)   # <-- your list of dicts\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# classified_df.to_csv(\"guess_strategy_labels.csv\", index=False)\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# classified_df.head()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m classified_df = run_classification_parallel(data, OPENROUTER_API_KEY, max_workers=\u001b[32m16\u001b[39m)\n\u001b[32m    203\u001b[39m classified_df.to_csv(\u001b[33m\"\u001b[39m\u001b[33mclassified_model_guess_strategies.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 191\u001b[39m, in \u001b[36mrun_classification_parallel\u001b[39m\u001b[34m(all_trials, api_key, max_workers)\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=\u001b[38;5;28mlen\u001b[39m(futures), desc=\u001b[33m\"\u001b[39m\u001b[33mClassifying batches\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m    190\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m concurrent.futures.as_completed(futures):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m             results.extend(f.result())\n\u001b[32m    192\u001b[39m             pbar.update(\u001b[32m1\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLMIdentifiersEnv/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLMIdentifiersEnv/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLMIdentifiersEnv/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.fn(*\u001b[38;5;28mself\u001b[39m.args, **\u001b[38;5;28mself\u001b[39m.kwargs)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 174\u001b[39m, in \u001b[36mrun_classification_parallel.<locals>.classify_batch\u001b[39m\u001b[34m(batch, client)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m    173\u001b[39m     prompt = build_prompt(p[\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m], p[\u001b[33m\"\u001b[39m\u001b[33mguessed_model\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     result = client.classify(prompt)\n\u001b[32m    175\u001b[39m     batch_results.append({\n\u001b[32m    176\u001b[39m         **p,\n\u001b[32m    177\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstrategies\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(result.get(\u001b[33m\"\u001b[39m\u001b[33mStrategies\u001b[39m\u001b[33m\"\u001b[39m, [])),\n\u001b[32m    178\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mjudge_explanation\u001b[39m\u001b[33m\"\u001b[39m: result.get(\u001b[33m\"\u001b[39m\u001b[33mReasoning_behind_classification\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    179\u001b[39m     })\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m batch_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLMIdentifiersEnv/lib/python3.11/site-packages/backoff/_sync.py:105\u001b[39m, in \u001b[36mretry_exception.<locals>.retry\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m details = {\n\u001b[32m     97\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m: target,\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m: args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33melapsed\u001b[39m\u001b[33m\"\u001b[39m: elapsed,\n\u001b[32m    102\u001b[39m }\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     ret = target(*args, **kwargs)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    107\u001b[39m     max_tries_exceeded = (tries == max_tries_value)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mORClient.classify\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;129m@backoff\u001b[39m.on_exception(backoff.expo, \u001b[38;5;167;01mException\u001b[39;00m, max_tries=\u001b[32m6\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclassify\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     wait = \u001b[38;5;28mself\u001b[39m.min_interval - (time.time() - \u001b[38;5;28mself\u001b[39m.last)\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wait > \u001b[32m0\u001b[39m:\n\u001b[32m     49\u001b[39m         time.sleep(wait)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ORClient' object has no attribute 'min_interval'"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1.  SETUP – strategy dictionary and OpenRouter helper\n",
    "# ------------------------------------------------------------------\n",
    "import json, time, backoff, pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# ••• fill in your key here •••\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# 3 strategies per model (use None for “N/A” placeholders)\n",
    "MODEL_STRATEGIES = {\n",
    "    \"claude\":  [\"Identity reveal\",\n",
    "                \"Insistent on being an assistant\",\n",
    "                \"Very meticulous in explanations\"],\n",
    "    \"deepseek\":[\"Identity reveal\",\n",
    "                \"Precise communication style\",\n",
    "                None],                            # only two real ones\n",
    "    \"gemini\":  [\"Creative storytelling\",\n",
    "                \"Engaging conversation\",\n",
    "                \"Technical and ethical acumen\"],\n",
    "    \"gpt\":     [\"Highly structured\",\n",
    "                \"Contextual understanding\",\n",
    "                \"Adaptability\"],\n",
    "    \"llama\":   [\"Less sophisticated\",\n",
    "                \"Open-source\",\n",
    "                \"Nuanced understanding\"],\n",
    "    \"mistral\": [\"Task capabilities\",\n",
    "                \"Concise and simple\",\n",
    "                \"Friendly\"],\n",
    "    \"qwen\":    [\"China-relevant knowledge\",\n",
    "                \"Formal, educational\",\n",
    "                \"Rigid conversation\"],\n",
    "}\n",
    "\n",
    "# helper → nice list without Nones\n",
    "def strategies_for(model):\n",
    "    return [s for s in MODEL_STRATEGIES[model] if s]\n",
    "\n",
    "class ORClient:\n",
    "    def __init__(self, api_key, model=\"google/gemini-2.5-flash-preview\", min_interval=1.5):\n",
    "        self.cli = OpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "        self.model = model\n",
    "        self.min_interval = min_interval  # <- critical line\n",
    "        self.last = 0\n",
    "\n",
    "    @backoff.on_exception(backoff.expo, Exception, max_tries=6)\n",
    "    def classify(self, prompt):\n",
    "        wait = self.min_interval - (time.time() - self.last)\n",
    "        if wait > 0:\n",
    "            time.sleep(wait)\n",
    "    \n",
    "        res = self.cli.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=300,\n",
    "            temperature=0,\n",
    "        )\n",
    "        self.last = time.time()\n",
    "        text = res.choices[0].message.content.strip()\n",
    "    \n",
    "        # Try extracting the JSON object\n",
    "        try:\n",
    "            # Remove triple-backtick code block wrappers\n",
    "            if text.startswith(\"```json\"):\n",
    "                text = text[7:].strip(\"` \\n\")\n",
    "            elif text.startswith(\"```\"):\n",
    "                text = text[3:].strip(\"` \\n\")\n",
    "    \n",
    "            # Find first { ... }\n",
    "            json_start = text.find(\"{\")\n",
    "            json_end = text.rfind(\"}\") + 1\n",
    "            json_str = text[json_start:json_end]\n",
    "    \n",
    "            return json.loads(json_str)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"\\n--- Failed to parse LLM output ---\")\n",
    "            print(text)\n",
    "            print(\"----------------------------------\\n\")\n",
    "            return {\n",
    "                \"Reasoning_behind_classification\": f\"Failed to parse: {text}\",\n",
    "                \"Strategies\": [\"Failed to parse\"]\n",
    "            }\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  BUILD THE CLASSIFICATION PROMPT\n",
    "# ------------------------------------------------------------------\n",
    "def build_prompt(reasoning, guessed_model):\n",
    "    allowed = strategies_for(guessed_model)\n",
    "    allowed_str = \"\\n\".join(f\"{i+1}. {s}\" for i, s in enumerate(allowed))\n",
    "    return f\"\"\"You are judging WHY a language model guessed another model.\n",
    "\n",
    "The guessed model: **{guessed_model}**\n",
    "\n",
    "Classify the justification below into ANY of these strategies\n",
    "(you may output multiple, or \"Other\" if none fit):\n",
    "\n",
    "{allowed_str}\n",
    "\n",
    "Justification:\n",
    "\\\"\\\"\\\"{reasoning}\\\"\\\"\\\"\n",
    "\n",
    "Return ONLY valid JSON like:\n",
    "{{  \n",
    "  \"Reasoning_behind_classification\": \"...explanation...\",\n",
    "  \"Strategies\": [\"{allowed[0]}\", \"{allowed[1]}\"]\n",
    "}}\"\"\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  EXTRACT (reasoning, guess) PAIRS FROM ALL TRIALS\n",
    "# ------------------------------------------------------------------\n",
    "def extract_pairs(trials):\n",
    "    pairs = []\n",
    "    for t in trials:\n",
    "        for agent_id in [\"agent_0\", \"agent_1\"]:\n",
    "            reasoning = (t.get(f\"{agent_id}_answer\") or \"\").strip()\n",
    "            guess = (t.get(f\"{agent_id}_guess\") or \"\").strip().lower()\n",
    "            if reasoning and guess in MODEL_STRATEGIES:\n",
    "                pairs.append({\n",
    "                    \"guesser\": agent_id,\n",
    "                    \"guessed_model\": guess,\n",
    "                    \"reasoning\": reasoning,\n",
    "                    \"trial_id\": t.get(\"seed\", \"na\")\n",
    "                })\n",
    "    return pairs\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  RUN EVERYTHING\n",
    "# ------------------------------------------------------------------\n",
    "from tqdm import tqdm  # for notebook-style progress bar\n",
    "\n",
    "def run_classification(all_trials):\n",
    "    client = ORClient(OPENROUTER_API_KEY)\n",
    "    pairs = extract_pairs(all_trials)\n",
    "    print(len(pairs))\n",
    "    rows = []\n",
    "\n",
    "    print(f\"Classifying {len(pairs)} guess reasonings...\\n\")\n",
    "\n",
    "    for p in tqdm(pairs, desc=\"Classifying guesses\"):\n",
    "        prompt = build_prompt(p[\"reasoning\"], p[\"guessed_model\"])\n",
    "        result = client.classify(prompt)\n",
    "        rows.append({\n",
    "            **p,\n",
    "            \"strategies\": \", \".join(result.get(\"Strategies\", [])),\n",
    "            \"judge_explanation\": result.get(\"Reasoning_behind_classification\", \"\")\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "def run_classification_parallel(all_trials, api_key, max_workers=4):\n",
    "    from copy import deepcopy\n",
    "\n",
    "    pairs = extract_pairs(all_trials)\n",
    "    print(f\"Classifying {len(pairs)} guess reasonings using {max_workers} threads...\\n\")\n",
    "\n",
    "    # Shared input split into batches\n",
    "    batch_size = math.ceil(len(pairs) / max_workers)\n",
    "    batches = [pairs[i:i + batch_size] for i in range(0, len(pairs), batch_size)]\n",
    "\n",
    "    # Create clients per worker\n",
    "    clients = [ORClient(api_key) for _ in range(len(batches))]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    def classify_batch(batch, client):\n",
    "        batch_results = []\n",
    "        for p in batch:\n",
    "            prompt = build_prompt(p[\"reasoning\"], p[\"guessed_model\"])\n",
    "            result = client.classify(prompt)\n",
    "            batch_results.append({\n",
    "                **p,\n",
    "                \"strategies\": \", \".join(result.get(\"Strategies\", [])),\n",
    "                \"judge_explanation\": result.get(\"Reasoning_behind_classification\", \"\")\n",
    "            })\n",
    "        return batch_results\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(classify_batch, batch, clients[i])\n",
    "            for i, batch in enumerate(batches)\n",
    "        ]\n",
    "\n",
    "        results = []\n",
    "        with tqdm(total=len(futures), desc=\"Classifying batches\") as pbar:\n",
    "            for f in concurrent.futures.as_completed(futures):\n",
    "                results.extend(f.result())\n",
    "                pbar.update(1)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5.  DO IT 🚀\n",
    "# ------------------------------------------------------------------\n",
    "# classified_df = run_classification(data)   # <-- your list of dicts\n",
    "# classified_df.to_csv(\"guess_strategy_labels.csv\", index=False)\n",
    "# classified_df.head()\n",
    "classified_df = run_classification_parallel(data, OPENROUTER_API_KEY, max_workers=16)\n",
    "classified_df.to_csv(\"classified_model_guess_strategies.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python LLMIdentifiersEnv",
   "language": "python",
   "name": "llmidentifiersenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
