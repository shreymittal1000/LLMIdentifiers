{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab2da9e-c166-4fcb-a043-e90c2e7bc5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrey/miniconda3/envs/LLMIdentifiersEnv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3efd6ee8-9fb3-4ec8-9b3e-faebd8294fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4218 valid JSON result files from '../results/base/' and its subfolders.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "folder_path = \"../results/base/\"\n",
    "data = []\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    entry = json.load(f)\n",
    "                    data.append(entry)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipped invalid JSON: {file_path} ({e})\")\n",
    "\n",
    "print(f\"Loaded {len(data)} valid JSON result files from '{folder_path}' and its subfolders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680cd8c1-fe0f-415b-af02-3bc8814e3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_STRATEGIES = {\n",
    "    \"claude\": [\n",
    "        \"Identity reveal\", \n",
    "        \"Insistent on being an assistant\", \n",
    "        \"Very meticulous in explanations\"\n",
    "    ],\n",
    "    \"deepseek\": [\n",
    "        \"Identity reveal\", \n",
    "        \"Precise communication style\", \n",
    "        \"N/A (Only guessed twice)\"\n",
    "    ],\n",
    "    \"gemini\": [\n",
    "        \"Creative storytelling\", \n",
    "        \"Engaging conversation\", \n",
    "        \"Technical and ethical acumen\"\n",
    "    ],\n",
    "    \"gpt\": [\n",
    "        \"Highly structured\", \n",
    "        \"Contextual understanding\", \n",
    "        \"Adaptability\"\n",
    "    ],\n",
    "    \"llama\": [\n",
    "        \"Less sophisticated\", \n",
    "        \"Open-source\", \n",
    "        \"Nuanced understanding\"\n",
    "    ],\n",
    "    \"mistral\": [\n",
    "        \"Task capabilities\", \n",
    "        \"Concise and simple\", \n",
    "        \"Friendly\"\n",
    "    ],\n",
    "    \"qwen\": [\n",
    "        \"China-relevant knowledge\", \n",
    "        \"Formal, educational\", \n",
    "        \"Rigid conversation\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b880d4f0-b1bf-4484-b584-a2efe5d29549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_specific_prompt(reasoning_text: str, model_name: str) -> str:\n",
    "    strategies = MODEL_STRATEGIES.get(model_name.lower(), [\"Unknown\"])\n",
    "    \n",
    "    strategies_str = \"\\n\".join([f\"- {s}\" for s in strategies])\n",
    "    example_json = {\n",
    "        \"Reasoning_behind_classification\": \"Explanation of your classification\",\n",
    "        \"Strategies\": strategies[:2]  # Pick first two for example\n",
    "    }\n",
    "\n",
    "    return f\"\"\"The following reasoning text was given for guessing that the other model is {model_name.title()}. \n",
    "\n",
    "Based on the text, classify it into one or more of the following known strategies associated with {model_name.title()}:\n",
    "\n",
    "{strategies_str}\n",
    "\n",
    "If none apply, use \"Other\".\n",
    "\n",
    "Reasoning:\n",
    "\\\"\\\"\\\"{reasoning_text.strip()}\\\"\\\"\\\"\n",
    "\n",
    "Respond ONLY in this JSON format:\n",
    "{json.dumps(example_json, indent=2)}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ec7138-56d7-4608-9de2-d6256abdbd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reasoning_tasks(data):\n",
    "    \"\"\"\n",
    "    Extract reasoning + guessed model from LLM Identifiers Game trials.\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    for trial in data:\n",
    "        for agent_id in ['agent_0', 'agent_1']:\n",
    "            answer = trial.get(f\"{agent_id}_answer\", {})\n",
    "            guessed_model = trial.get(f\"{agent_id}_guess\", \"\").strip()\n",
    "            reasoning = answer.get(\"reasoning\", \"\").strip() if isinstance(answer, dict) else \"\"\n",
    "\n",
    "            if guessed_model and reasoning:\n",
    "                tasks.append({\n",
    "                    \"guesser\": agent_id,\n",
    "                    \"guessed_model\": guessed_model.lower(),\n",
    "                    \"reasoning\": reasoning,\n",
    "                    \"trial_metadata\": {\n",
    "                        \"model_0\": trial.get(\"model_general_name_0\"),\n",
    "                        \"model_1\": trial.get(\"model_general_name_1\"),\n",
    "                        \"conversation_id\": trial.get(\"conversation_id\", \"unknown\")\n",
    "                    }\n",
    "                })\n",
    "    return tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea238684-ab5d-4d2e-8c13-4f9d85e41300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import backoff\n",
    "\n",
    "class OpenRouterClient:\n",
    "    def __init__(self, api_key, model_name=\"openai/gpt-4o-mini\"):\n",
    "        from openai import OpenAI\n",
    "        self.client = OpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "        self.model_name = model_name\n",
    "        self.last_request_time = 0\n",
    "        self.min_interval = 1.5  # seconds\n",
    "\n",
    "    @backoff.on_exception(backoff.expo, Exception, max_tries=6)\n",
    "    def classify(self, prompt):\n",
    "        import time, json\n",
    "        elapsed = time.time() - self.last_request_time\n",
    "        if elapsed < self.min_interval:\n",
    "            time.sleep(self.min_interval - elapsed)\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=300\n",
    "        )\n",
    "\n",
    "        self.last_request_time = time.time()\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        try:\n",
    "            json_start = content.find('{')\n",
    "            json_end = content.rfind('}') + 1\n",
    "            return json.loads(content[json_start:json_end])\n",
    "        except Exception:\n",
    "            return {\n",
    "                \"Reasoning_behind_classification\": content,\n",
    "                \"Strategies\": [\"Failed to classify\"]\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239419f0-fee5-4f1e-816e-1014f5947ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_all(data, api_key):\n",
    "    client = OpenRouterClient(api_key)\n",
    "    tasks = extract_reasoning_tasks(data)\n",
    "    results = []\n",
    "\n",
    "    for task in tqdm(tasks):\n",
    "        guessed_model = task['guessed_model']\n",
    "        reasoning = task['reasoning']\n",
    "        prompt = build_model_specific_prompt(reasoning, guessed_model)\n",
    "        \n",
    "        result = client.classify(prompt)\n",
    "        results.append({\n",
    "            \"guesser\": task['guesser'],\n",
    "            \"guessed_model\": guessed_model,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"strategies\": result.get(\"Strategies\", []),\n",
    "            \"explanation\": result.get(\"Reasoning_behind_classification\", \"\"),\n",
    "            **task[\"trial_metadata\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "146293b8-7673-4415-bd7d-69ee5493cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have the list of dicts as `data`\n",
    "api_key = \"your-openrouter-api-key\"\n",
    "df_results = classify_all(data, api_key)\n",
    "df_results.to_csv(\"llm_guess_strategy_classifications.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python LLMIdentifiersEnv",
   "language": "python",
   "name": "llmidentifiersenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
